{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff05135",
   "metadata": {},
   "source": [
    "## sub-task 1 제출 스크립트\n",
    "ETRI FASHION-HOW Season 5 task1 제출코드입니다.\n",
    "#### 주의: 반드시 본 파일을 이용하여 제출을 수행해야 하며 파일의 이름은 task.ipynb로 유지되어야 합니다.\n",
    "- 작성하신 추론용 코드(예: test.py)를 본 스크립트 내의 etri_task1_submit() 함수로 작동되게끔 삽입하는 것으로 결과 제출을 수행할 수 있습니다.\n",
    "코드는 크게 4가지 파트로 구성되며, 해당 파트의 특성을 지켜서 내용을 편집하시면 되겠습니다.\n",
    "1. 제출용 aifactory 라이브러리 설치\n",
    "2. etri_task1_submit() 함수 편집 (추론 스크립트)\n",
    "3. submit() 함수로 wrapping\n",
    "4. if __name__ == \"__main__\" 조건문을 이용한 제출 수행\n",
    "\n",
    "※ 가능하면 제출시에는 포함되어 있는 train data를 폴더에서 제외하고 제출하시는 편이 좋습니다.\n",
    "- 파일 크기 감소 → 업로드 시간 감소 → 전체 추론 수행 시간 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33268b01",
   "metadata": {},
   "source": [
    "### 1. 제출용 aifactory 라이브러리 설치\n",
    "#### 결과 전송에 필요하므로 아래와 같이 aifactory 라이브러리가 반드시 최신버전으로 설치될 수 있게끔 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f3f0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aifactory\n",
      "  Downloading aifactory-1.9.3-py3-none-any.whl.metadata (344 bytes)\n",
      "Collecting pipreqs (from aifactory)\n",
      "  Downloading pipreqs-0.5.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting ipynbname (from aifactory)\n",
      "  Downloading ipynbname-2024.1.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting gdown (from aifactory)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: requests in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from aifactory) (2.32.3)\n",
      "Requirement already satisfied: IPython in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from aifactory) (8.26.0)\n",
      "Collecting beautifulsoup4 (from gdown->aifactory)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from gdown->aifactory) (3.13.1)\n",
      "Requirement already satisfied: tqdm in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from gdown->aifactory) (4.66.4)\n",
      "Requirement already satisfied: ipykernel in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from ipynbname->aifactory) (6.29.5)\n",
      "Requirement already satisfied: decorator in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from IPython->aifactory) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from IPython->aifactory) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from IPython->aifactory) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from IPython->aifactory) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from IPython->aifactory) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from IPython->aifactory) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from IPython->aifactory) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from IPython->aifactory) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from IPython->aifactory) (0.4.6)\n",
      "Collecting docopt==0.6.2 (from pipreqs->aifactory)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting IPython (from aifactory)\n",
      "  Downloading ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting nbconvert<8.0.0,>=7.11.0 (from pipreqs->aifactory)\n",
      "  Downloading nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting yarg==0.1.9 (from pipreqs->aifactory)\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting backcall (from IPython->aifactory)\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pickleshare (from IPython->aifactory)\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from requests->aifactory) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from requests->aifactory) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from requests->aifactory) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from requests->aifactory) (2024.7.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from jedi>=0.16->IPython->aifactory) (0.8.4)\n",
      "Collecting bleach!=5.0.0 (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (3.1.3)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (5.7.2)\n",
      "Collecting jupyterlab-pygments (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2.1.5)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (24.1)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading tinycss2-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->aifactory) (0.2.13)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown->aifactory)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (1.8.5)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (8.6.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (6.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (26.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (6.4.1)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown->aifactory)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from stack-data->IPython->aifactory) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from stack-data->IPython->aifactory) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from stack-data->IPython->aifactory) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from asttokens>=2.1.0->stack-data->IPython->aifactory) (1.16.0)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->ipynbname->aifactory) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from jupyter-core>=4.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\workspace\\fashion-how\\.venv\\lib\\site-packages (from jupyter-core>=4.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (306)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading attrs-24.1.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory)\n",
      "  Downloading rpds_py-0.19.1-cp311-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Downloading aifactory-1.9.3-py3-none-any.whl (9.2 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading ipynbname-2024.1.0.0-py3-none-any.whl (4.3 kB)\n",
      "Downloading pipreqs-0.5.0-py3-none-any.whl (33 kB)\n",
      "Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
      "   ---------------------------------------- 0.0/798.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 798.3/798.3 kB 35.7 MB/s eta 0:00:00\n",
      "Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Downloading nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "Downloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
      "Downloading fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading attrs-24.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.19.1-cp311-none-win_amd64.whl (210 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13774 sha256=49f014ce95d83264e4a97d81c6efa0c14880678d30c5e59362be6196fdf6ef2f\n",
      "  Stored in directory: c:\\users\\cywell\\appdata\\local\\pip\\cache\\wheels\\1a\\b0\\8c\\4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "Successfully built docopt\n",
      "Installing collected packages: webencodings, pickleshare, fastjsonschema, docopt, backcall, tinycss2, soupsieve, rpds-py, PySocks, pandocfilters, mistune, jupyterlab-pygments, defusedxml, bleach, attrs, yarg, referencing, beautifulsoup4, jsonschema-specifications, IPython, gdown, jsonschema, nbformat, ipynbname, nbclient, nbconvert, pipreqs, aifactory\n",
      "  Attempting uninstall: IPython\n",
      "    Found existing installation: ipython 8.26.0\n",
      "    Uninstalling ipython-8.26.0:\n",
      "      Successfully uninstalled ipython-8.26.0\n",
      "Successfully installed IPython-8.12.3 PySocks-1.7.1 aifactory-1.9.3 attrs-24.1.0 backcall-0.2.0 beautifulsoup4-4.12.3 bleach-6.1.0 defusedxml-0.7.1 docopt-0.6.2 fastjsonschema-2.20.0 gdown-5.2.0 ipynbname-2024.1.0.0 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 jupyterlab-pygments-0.3.0 mistune-3.0.2 nbclient-0.10.0 nbconvert-7.16.4 nbformat-5.10.4 pandocfilters-1.5.1 pickleshare-0.7.5 pipreqs-0.5.0 referencing-0.35.1 rpds-py-0.19.1 soupsieve-2.5 tinycss2-1.3.0 webencodings-0.5.1 yarg-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install -U aifactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef113da",
   "metadata": {},
   "source": [
    "### 2. etri_task1_submit() 함수 편집 (추론 스크립트)\n",
    "#### etri_task1_submit() 편집 시 주의사항\n",
    "\n",
    "1. 아래 etri_task1_submit() 함수 내에 전체 추론 실행 코드를 삽입하고 결과를 dataframe으로 return하게끔 구성\n",
    "   - Baseline이 아닌 다른 모델을 사용하는 경우에도 동일\n",
    "2. 함수 내에서는 import * 가 적용되지 않으므로 필요한 import object를 직접 입력\n",
    "   - 반드시 함수 내에서 import가 이루어져야 합니다.\n",
    "3. argparse 사용시 args, _ = parser.parse_known_args()로 인자 지정\n",
    "   args = parser.parse_args()는 jupyter에서 오류가 발생합니다!!!\n",
    "4. 모델 내부의 경로는 ./ 으로 경로를 지정합니다. (예: weight 파일 경로 = ./model/...)\n",
    "5. 데이터는 **/aif/Dataset/** 경로 아래에 있습니다. (코드 내용 참조) \n",
    "6. return할 결과물과 양식에 유의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d05b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etri_task1_submit():\n",
    "\n",
    "    from dataset import ETRIDataset_emo\n",
    "    from networks import ResExtractor, Baseline_ResNet_emo, Baseline_MNet_emo\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    import torch\n",
    "    import torch.utils.data\n",
    "    import torch.utils.data.distributed\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    net = Baseline_MNet_emo().to(DEVICE)\n",
    "    trained_weights = torch.load(\n",
    "        \".C:\\workspace\\FASHION-HOW\\Fashion-How_2024_subtask1\\check_points\\EVATiny\\EVATiny_15Epoch.pth\",\n",
    "        map_location=DEVICE,\n",
    "    )  # 자기 모델 경로를 지정합니다\n",
    "    net.load_state_dict(trained_weights)\n",
    "\n",
    "    df = pd.read_csv(\"/aif/Dataset/Fashion-How24_sub1_test.csv\")  # 제출 시 데이터 경로 준수. /aif/ 아래에 있습니다.\n",
    "    val_dataset = ETRIDataset_emo(\n",
    "        df, base_path=\"/aif/Dataset/test/\"\n",
    "    )  # 제출 시 데이터 경로 준수. /aif/ 아래에 있습니다.\n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=64, shuffle=False, num_workers=0\n",
    "    )  # 반드시 shuffle=False\n",
    "\n",
    "    daily_pred_list = np.array([])\n",
    "    gender_pred_list = np.array([])\n",
    "    embel_pred_list = np.array([])\n",
    "\n",
    "    for j, sample in tqdm(enumerate(val_dataloader)):\n",
    "        for key in sample:\n",
    "            sample[key] = sample[key].to(DEVICE)\n",
    "        out_daily, out_gender, out_embel = net(sample)\n",
    "\n",
    "        daily_pred = out_daily\n",
    "        _, daily_indx = daily_pred.max(1)\n",
    "        daily_pred_list = np.concatenate([daily_pred_list, daily_indx.cpu()], axis=0)\n",
    "\n",
    "        gender_pred = out_gender\n",
    "        _, gender_indx = gender_pred.max(1)\n",
    "        gender_pred_list = np.concatenate([gender_pred_list, gender_indx.cpu()], axis=0)\n",
    "\n",
    "        embel_pred = out_embel\n",
    "        _, embel_indx = embel_pred.max(1)\n",
    "        embel_pred_list = np.concatenate([embel_pred_list, embel_indx.cpu()], axis=0)\n",
    "\n",
    "    # 예측 결과를 dataframe으로 변환한 다음 함수의 결과로 return합니다.\n",
    "    # 'image_name', 'daily', 'gender', 'embel'의 컬럼명과 image_name의 샘플 순서를 지켜주시기 바랍니다.\n",
    "    # Baseline이 아닌 다른 모델을 사용하는 경우에도 같은 형식의 dataframe으로 return할 수 있도록 합니다.\n",
    "    out = pd.DataFrame(\n",
    "        {\"image_name\": df[\"image_name\"], \"daily\": daily_pred_list, \"gender\": gender_pred_list, \"embel\": embel_pred_list}\n",
    "    )\n",
    "\n",
    "    return out  # 반드시 추론결과를 return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9ff6a",
   "metadata": {},
   "source": [
    "### 3. submit() 함수로 wrapping\n",
    "#### 반드시 아래와 같이 submit() 이라는 함수로 위에 정의된 etri_task1_submit 함수를 wrapping해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8462eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit():\n",
    "    return etri_task1_submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f41b0e",
   "metadata": {},
   "source": [
    "### 4. if name == \"main\" 조건문을 이용한 제출 수행\n",
    "#### 아래와 같이 if __name__ == \"__main__\" 구문 내에서 제출 함수가 실행되게끔 합니다.\n",
    "#### ※ task별, 참가자별로 key가 다릅니다. 잘못 입력하지 않도록 유의바랍니다.\n",
    "- key는 각팀 팀장분에게 메일로 전달된 안내네서 task별로 확인하실 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3468396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file : task.py\n",
      "python\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#-----------------------------------------------------#\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     \u001b[43maif\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbaseline_task1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# 본인의 모델명 입력(버전 관리에 용이하게끔 편의에 맞게 지정합니다)\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m78587602-4e70-41db-b4cc-bd0e952d8985\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                                   \u001b[49m\u001b[38;5;66;43;03m# 본인의 task key 입력\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m               \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m                                 \u001b[49m\u001b[38;5;66;43;03m# 3.에서 wrapping한 submit function\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m               \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m#-----------------------------------------------------#\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t)\n",
      "File \u001b[1;32mc:\\workspace\\FASHION-HOW\\.venv\\Lib\\site-packages\\aifactory\\score.py:65\u001b[0m, in \u001b[0;36msubmit\u001b[1;34m(model_name, key, func)\u001b[0m\n\u001b[0;32m     62\u001b[0m   main_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile : \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main_name))\n\u001b[1;32m---> 65\u001b[0m \u001b[43mmake_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m file_size \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./aif.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m gsize \u001b[38;5;241m=\u001b[39m file_size \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[1;32mc:\\workspace\\FASHION-HOW\\.venv\\Lib\\site-packages\\aifactory\\score.py:54\u001b[0m, in \u001b[0;36mmake_zip\u001b[1;34m(main_name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:       \n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m path \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m path \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_data\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m path \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maif.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m file :      \n\u001b[1;32m---> 54\u001b[0m       \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompress_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZIP_DEFLATED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\zipfile.py:1805\u001b[0m, in \u001b[0;36mZipFile.write\u001b[1;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[0;32m   1802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1803\u001b[0m     zinfo\u001b[38;5;241m.\u001b[39m_compresslevel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompresslevel\n\u001b[1;32m-> 1805\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[0;32m   1806\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(src, dest, \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import aifactory.score as aif\n",
    "import time\n",
    "t = time.time()\n",
    "if __name__ == \"__main__\":\n",
    "    #-----------------------------------------------------#\n",
    "    aif.submit(model_name=\"baseline_task1\",             # 본인의 모델명 입력(버전 관리에 용이하게끔 편의에 맞게 지정합니다)\n",
    "               key=\"78587602-4e70-41db-b4cc-bd0e952d8985\",                                   # 본인의 task key 입력\n",
    "               func=submit                                 # 3.에서 wrapping한 submit function\n",
    "               )\n",
    "    #-----------------------------------------------------#\n",
    "    print(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e41e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
